{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\khayyam\\algorithms.py:19: UserWarning: The C extension is not available. Switching to fallback python pure algorithms,so it's about 1000X slower than C implementation of the algorithms.\n",
      "  \"The C extension is not available. Switching to fallback python pure algorithms,\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from khayyam import *\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from furl import furl\n",
    "import psycopg2\n",
    "import datetime\n",
    "import pandas.io.sql as psql\n",
    "from selenium.common.exceptions import NoSuchElementException  \n",
    "from selenium.webdriver.support.ui import Select\n",
    "import re\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "db_username=\"Jay\"\n",
    "db_pass=\"Mehrad1\"\n",
    "db_host=\"127.0.0.1\"\n",
    "db_port=\"5432\"\n",
    "db_database=\"FinWisev10\"\n",
    "def Translate_NotesPages(driver):\n",
    "    wholefile=str(driver.page_source)\n",
    "    wholefile=wholefile[(wholefile.find('\"cells\":['))+8:]\n",
    "    wholefile=wholefile[:wholefile.find('</script>')-10]\n",
    "    wholefile=wholefile[:wholefile.rfind(']')]\n",
    "    wholefile=wholefile[:wholefile.rfind(']')+1]\n",
    "    wholefile=wholefile.replace('[','')\n",
    "    wholefile=wholefile.replace(']','')\n",
    "    wholefile=wholefile.replace('\\u200c', '')\n",
    "    #wholefile=wholefile.replace('\"','\\'')\n",
    "    listofDicts=[]\n",
    "    for i in range(1,wholefile.count('{')+1):\n",
    "        try:\n",
    "            temp=wholefile[find_nth(wholefile,'{',i):find_nth(wholefile,'}',i)+1]\n",
    "            listofDicts.append(json.loads(temp))\n",
    "        except:\n",
    "            continue\n",
    "    df1=pd.DataFrame(listofDicts)\n",
    "    listofDicts2=[]\n",
    "    for i in range(1,wholefile.count(',\"title_En\":')+1):\n",
    "        try:\n",
    "            temp=wholefile[find_nth(wholefile,',\"title_En\":',i)-20:find_nth(wholefile,',\"title_En\":',i)+200]\n",
    "            listofDicts2.append(temp)\n",
    "        except:\n",
    "            continue\n",
    "    highlvlheaderstemp={}\n",
    "    highlvlheaders={}\n",
    "    for i in listofDicts2:\n",
    "        highlvlheaderstemp[re.findall('\"metaTableId.*title_Fa',i)[0][:-10].split(',')[0].split(':')[1]]=re.findall('\"metaTableId.*title_Fa',i)[0][:-10].split(',')[1].split(':')[1]\n",
    "    for key,val in highlvlheaderstemp.items():\n",
    "        highlvlheaders[key]=val.replace('\"','')\n",
    "    hlvldf=pd.DataFrame.from_dict(highlvlheaders,orient='index')\n",
    "    hlvldf.reset_index(inplace=True)\n",
    "    hlvldf.columns=['metaID','highlvlDFName'] \n",
    "    hlvldf['metaID']=hlvldf['metaID'].astype(int)   \n",
    "    ALLDFS=[]\n",
    "    TableIDs=df1.metaTableId.unique()\n",
    "    for metatableID in TableIDs:\n",
    "        try:\n",
    "            dftemp=df1[df1['metaTableId']==metatableID]\n",
    "            dfheaders=dftemp[dftemp['cellGroupName']=='Header'] \n",
    "            if len(dfheaders)==0:\n",
    "                rawdict={}\n",
    "                rawdict[metatableID]='-'.join(dftemp.value.tolist())\n",
    "                DFt=pd.DataFrame.from_dict(rawdict,orient='index')\n",
    "                DFt.reset_index(inplace=True)\n",
    "                DFt.columns=['metaID','desc']\n",
    "                ALLDFS.append(DFt)\n",
    "            else:\n",
    "                \n",
    "                dfheaders=dfheaders[['address','rowSpan','rowCode','rowSequence','colSpan','columnCode','columnSequence','value']]\n",
    "                for index,row in dfheaders.iterrows():\n",
    "                    dfheaders.at[index,'level']=row['rowCode']-dfheaders.rowCode.min()   \n",
    "                dfheaders['columnSequence']=dfheaders['columnSequence'].astype(int)  \n",
    "                for k in dfheaders.level.unique().tolist():\n",
    "                    if k!=0:\n",
    "                        dfheaderstemp=dfheaders[dfheaders['level']==k]\n",
    "                        for index,row in dfheaderstemp.iterrows():\n",
    "                            df3=dfheaders[dfheaders['level']<=row['level']-1]\n",
    "                            df3.sort_values(by=['columnSequence'],inplace=True)\n",
    "                            parent=df3[df3['columnSequence']<=row['columnSequence']].iloc[-1].address\n",
    "                            dfheaderstemp.at[index,'parent']=parent\n",
    "                            dfheaders.loc[dfheaders['address']==row['address'],'parent']=parent\n",
    "                dfheaders.sort_values(by=['level'],ascending=False,inplace=True)  \n",
    "                listofDFS=[]\n",
    "                for i in range(int(dfheaders.level.max())+1):\n",
    "                    listofDFS.append(dfheaders.copy()) \n",
    "                dfdf=listofDFS[0]\n",
    "                for i in range(int(dfheaders.level.max())):\n",
    "                    try:\n",
    "                        dfdf=pd.merge(dfdf,listofDFS[i+1],how='left',left_on='parent',right_on='address')\n",
    "                    except:\n",
    "                        dfdf=pd.merge(dfdf,listofDFS[i+1],how='left',left_on='parent_y',right_on='address') \n",
    "                col=[]\n",
    "                titles=[]\n",
    "                for index,row in dfdf.iterrows():\n",
    "                    title=''\n",
    "                    if (row[6]) not in col:\n",
    "                        col.append(row[6])\n",
    "                        for key,value in row.iteritems():\n",
    "                            if 'value' in key:\n",
    "                                if str(value)!='nan':\n",
    "                                    title=str(value)+' '+title\n",
    "                        titles.append(title)\n",
    "                dictf={}\n",
    "                for i in range(len(col)):\n",
    "                    dictf[col[i]]=titles[i] \n",
    "                dictf2={}\n",
    "                for k in sorted(dictf):\n",
    "                    dictf2[k]=(dictf[k])\n",
    "                DFFinal=pd.DataFrame(columns=dictf2.values()) \n",
    "                df1values=dftemp[dftemp['cellGroupName']=='Body'] \n",
    "                for key,val in dictf2.items():\n",
    "                    DFFinal[val]=df1values[df1values['columnSequence']==key].value.tolist()            \n",
    "                DFFinal=DFFinal[DFFinal[DFFinal.columns[0]]!='']\n",
    "                DFFinal['metaID']=int(metatableID)\n",
    "                ALLDFS.append(DFFinal)\n",
    "        except:\n",
    "            continue \n",
    "    Mdicts={}\n",
    "    for index,row in hlvldf.iterrows():\n",
    "        for k in ALLDFS:\n",
    "            try:\n",
    "                if k.metaID.unique().tolist()[0]==row['metaID']:\n",
    "                    Mdicts[row['highlvlDFName']]=k\n",
    "            except:\n",
    "                continue   \n",
    "                \n",
    "    return Mdicts                \n",
    "def InsertAllData(CID,allData):\n",
    "    readytoInsert={}\n",
    "    for i in allData:\n",
    "        for key,value in i.items():\n",
    "            if key!='null':\n",
    "                ss=str(value.to_csv())\n",
    "                readytoInsert[key]=ss\n",
    "    Final=pd.DataFrame().from_dict(readytoInsert,orient='index')\n",
    "    Final.reset_index(inplace=True)\n",
    "    Final.columns=['title','Data']\n",
    "    Final['report_ID']=CID\n",
    "    try:\n",
    "        connection = psycopg2.connect(user=db_username,\n",
    "                                      password=db_pass,\n",
    "                                      host=db_host,\n",
    "                                      port=db_port,\n",
    "                                      database=db_database)\n",
    "        cursor = connection.cursor()\n",
    "        postgres_insert_query = \"\"\"\n",
    "         DO \n",
    "            $$\n",
    "            BEGIN\n",
    "                IF NOT EXISTS (select from statement.\"PreNotes\" where \"report_ID\"=%(report_ID)s and \"tableID\"=%(title)s) THEN\n",
    "                INSERT INTO statement.\"PreNotes\"(\n",
    "                \"report_ID\", \"tableID\", \"Datatable\")\n",
    "                VALUES (%(report_ID)s, %(title)s, %(Data)s);\n",
    "                END IF;\n",
    "            END\n",
    "            $$ \n",
    "\n",
    "        \"\"\"\n",
    "        cursor.executemany(postgres_insert_query,Final.to_dict(orient='records'))\n",
    "        connection.commit()\n",
    "        updateMRquery = \"\"\"\n",
    "        UPDATE codalraw.\"SheetsConverted\"\n",
    "        SET \"Exist_Interpret\"=True\n",
    "        WHERE \"report_ID\"=%s;\n",
    "        \"\"\"\n",
    "        RecordMR=([CID])\n",
    "        cursor.execute(updateMRquery, RecordMR)\n",
    "        connection.commit()\n",
    "        print(str(CID)+' Notes Done')\n",
    "    except(Exception, psycopg2.Error) as error:\n",
    "            if(connection):\n",
    "                print(\"Failed to Insert CF\", error)\n",
    "    finally:\n",
    "        if(connection):\n",
    "            cursor.close()\n",
    "            connection.close()    \n",
    "\n",
    "def UpdateError(driver,CodalRaw_ID):\n",
    "    Error=False\n",
    "    if check_exists_by_xpath(driver,'//*[text()=\"متاسفانه سیستم با خطا مواجه شده است.\"]'):\n",
    "        Error=True\n",
    "    if check_exists_by_xpath(driver,'//*[@id=\"Table2\"]//span[text()=\"ضمائم\"]'):\n",
    "        Error=True\n",
    "    if Error:\n",
    "        InsertError(CodalRaw_ID)\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "def InsertError(CodalRaw_ID):\n",
    "    try:\n",
    "        connection = psycopg2.connect(user=db_username,\n",
    "                                    password=db_pass,\n",
    "                                    host=db_host,\n",
    "                                    port=db_port,\n",
    "                                    database=db_database)\n",
    "        cursor = connection.cursor()\n",
    "        postgres_insert_query = \"\"\"\n",
    "        \n",
    "        UPDATE codalraw.\"allrawReports\" SET \"Available\"=False WHERE \"TracingNo\"=%s\n",
    "\n",
    "        \"\"\"\n",
    "        cursor.execute(postgres_insert_query,(CodalRaw_ID,))\n",
    "        connection.commit() \n",
    "    except(Exception, psycopg2.Error) as error:\n",
    "            if(connection):\n",
    "                print(\"Failed to Update Error sheets\", error)\n",
    "                log_it('Failed to Update Error sheets -')\n",
    "    finally:\n",
    "        if(connection):\n",
    "            cursor.close()\n",
    "            connection.close()   \n",
    "def check_exists_by_xpath(driver,xpath):\n",
    "    try:\n",
    "        driver.find_element_by_xpath(xpath)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start\n",
    "def roundTheFloats(x):\n",
    "    if(type(get_true_value(x))==float):\n",
    "        return int(round(get_true_value(x)))\n",
    "    else:\n",
    "        return x\n",
    "def isfloat(x):\n",
    "    try:\n",
    "        a = float(x)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "def isint(x):\n",
    "    try:\n",
    "        a = float(x)\n",
    "        b = int(a)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    else:\n",
    "        return a == b\n",
    "def log_it(text):\n",
    "    try:\n",
    "        connection = psycopg2.connect(user=db_username,\n",
    "                                          password=db_pass,\n",
    "                                          host=db_host,\n",
    "                                          port=db_port,\n",
    "                                          database=db_database)\n",
    "        cursor = connection.cursor()\n",
    "        postgres_insert_query = \"\"\"\n",
    "          \n",
    "          INSERT INTO public._log(\n",
    "            date, action,source)\n",
    "                VALUES (%s, %s,%s);\n",
    "        \"\"\"\n",
    "    \n",
    "        record_to_insert = (str(datetime.datetime.now()),text,'N52')\n",
    "        \n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "    except(Exception, psycopg2.Error) as error:\n",
    "        if(connection):\n",
    "            print(\"Failed to insert log\", error)\n",
    "    finally:\n",
    "        if(connection):\n",
    "            cursor.close()\n",
    "            connection.close()           \n",
    "def get_true_value(x):\n",
    "    x=str(x)\n",
    "    negative=False\n",
    "    if(',' in x):\n",
    "        x=x.replace(',','')\n",
    "    if('(' in x and ')' in x ):\n",
    "        x=x.replace(')','')\n",
    "        x=x.replace('(','')\n",
    "        negative=True\n",
    "    if isint(x):\n",
    "        x=x.split('.')[0]\n",
    "        if negative:\n",
    "            x=int(x)*-1\n",
    "        else:\n",
    "            x=int(x)\n",
    "    else:\n",
    "        if isfloat(x):\n",
    "            if negative:\n",
    "                x=float(x)*-1\n",
    "            else:\n",
    "                x=float(x)\n",
    "    return x    \n",
    "def get_unconverted():\n",
    "    try:\n",
    "        connection = psycopg2.connect(user=db_username,\n",
    "                                          password=db_pass,\n",
    "                                          host=db_host,\n",
    "                                          port=db_port,\n",
    "                                          database=db_database)\n",
    "        cursor = connection.cursor()\n",
    "        df = psql.read_sql(\"\"\"\n",
    "\n",
    "            select \"report_ID\",\"HtmlUrl\" from codalraw.\"SheetsConverted\" inner join\n",
    "            codalraw.\"allrawReports\" on \"report_ID\"=\"TracingNo\" where (\"Exist_Interpret\"=False )\n",
    "        \"\"\", connection)\n",
    "        return df\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "            if(connection):\n",
    "                print(\"Failed to read links\", error)\n",
    "    finally:\n",
    "            if(connection):\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "def chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    return (l[i:i+n] for i in range(0, len(l), n))  \n",
    "\n",
    "def get_options(driver):\n",
    "    listOFOptions=[]\n",
    "    select = Select(driver.find_element_by_id('ddlTable'))\n",
    "    for i in select.options:\n",
    "        listOFOptions.append(str(i.text).strip().replace('\\u200c',''))\n",
    "    return listOFOptions               \n",
    "                     \n",
    "def RUN():\n",
    "    driver=webdriver.Chrome()\n",
    "    driver.maximize_window()  \n",
    "    df=get_unconverted()\n",
    "    for index,row in df.head(10).iterrows():\n",
    "        driver.get('https://codal.ir'+str(row['HtmlUrl']))\n",
    "        allData=[]\n",
    "        listof=[]\n",
    "        for i in get_options(driver):\n",
    "            if ('تفسیر') in str(i):\n",
    "                listof.append(i)\n",
    "        \n",
    "        for k in listof:\n",
    "            select = Select(driver.find_element_by_id('ddlTable'))\n",
    "            select.select_by_visible_text(k)\n",
    "            allData.append(Translate_NotesPages(driver))\n",
    "            time.sleep(5) \n",
    "        InsertAllData(row['report_ID'],allData)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680422 Notes Done\n",
      "677322 Notes Done\n",
      "680612 Notes Done\n",
      "678382 Notes Done\n",
      "680288 Notes Done\n",
      "679078 Notes Done\n",
      "680717 Notes Done\n",
      "677521 Notes Done\n",
      "680129 Notes Done\n",
      "679490 Notes Done\n"
     ]
    }
   ],
   "source": [
    "RUN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
