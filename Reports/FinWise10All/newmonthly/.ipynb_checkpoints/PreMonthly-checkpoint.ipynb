{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\khayyam\\algorithms.py:19: UserWarning: The C extension is not available. Switching to fallback python pure algorithms,so it's about 1000X slower than C implementation of the algorithms.\n",
      "  \"The C extension is not available. Switching to fallback python pure algorithms,\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from khayyam import *\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from furl import furl\n",
    "import psycopg2\n",
    "import datetime\n",
    "import pandas.io.sql as psql\n",
    "from selenium.common.exceptions import NoSuchElementException  \n",
    "from selenium.webdriver.support.ui import Select\n",
    "import requests\n",
    "from lxml import html\n",
    "import re\n",
    "db_username=\"Jay\"\n",
    "db_pass=\"Mehrad1\"\n",
    "db_host=\"127.0.0.1\"\n",
    "db_port=\"5432\"\n",
    "db_database=\"FinWisev10\"\n",
    "def check_exists_by_xpath(driver,xpath):\n",
    "    try:\n",
    "        driver.find_element_by_xpath(xpath)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "def get_unconverted():\n",
    "    try:\n",
    "        connection = psycopg2.connect(user=db_username,\n",
    "                                          password=db_pass,\n",
    "                                          host=db_host,\n",
    "                                          port=db_port,\n",
    "                                          database=db_database)\n",
    "        cursor = connection.cursor()\n",
    "        df = psql.read_sql(\"\"\"\n",
    "          \n",
    "             select P.\"report_ID\",R.\"HtmlUrl\"\n",
    "            from monthly.\"PreMonthly\" as P inner join codalraw.\"allrawReports\" as R on P.\"report_ID\"=R.\"TracingNo\"\n",
    "            WHERE P.\"Type\"='Product' and P.converted=False order by \"report_ID\" desc\n",
    "            \"\"\"\n",
    "        \n",
    "\n",
    "                           , connection)\n",
    "        return df\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "            if(connection):\n",
    "                print(\"Failed to read links\", error)\n",
    "    finally:\n",
    "            if(connection):\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "def roundTheFloats(x):\n",
    "    if(type(get_true_value(x))==float):\n",
    "        return int(round(get_true_value(x)))\n",
    "    else:\n",
    "        return x        \n",
    "    \n",
    "def get_announcments(driver):\n",
    "    results={}\n",
    "    if check_exists_by_xpath(driver,'//a[@id=\"ctl00_cphBody_ucNavigateToNextPrevLetter_hlPrevVersion\"]'):\n",
    "        linktoprevious=driver.find_element_by_xpath('//a[@id=\"ctl00_cphBody_ucNavigateToNextPrevLetter_hlPrevVersion\"]').text\n",
    "        previousAnnouncment=[int(s) for s in str.split(linktoprevious) if s.isdigit()][0]\n",
    "    else:\n",
    "        previousAnnouncment=0\n",
    "    if check_exists_by_xpath(driver,'//a[@id=\"ctl00_cphBody_ucNavigateToNextPrevLetter_hlNewVersion\"]'):\n",
    "        linktonext=driver.find_element_by_xpath('//a[@id=\"ctl00_cphBody_ucNavigateToNextPrevLetter_hlNewVersion\"]').text\n",
    "        nextAnnouncment=[int(s) for s in str.split(linktonext) if s.isdigit()][0]\n",
    "    else:\n",
    "        nextAnnouncment=0\n",
    "    results['Last']=previousAnnouncment\n",
    "    results['Next']=nextAnnouncment\n",
    "    return results\n",
    "def log_it(text):\n",
    "    try:\n",
    "        connection = psycopg2.connect(user=db_username,\n",
    "                                          password=db_pass,\n",
    "                                          host=db_host,\n",
    "                                          port=db_port,\n",
    "                                          database=db_database)\n",
    "        cursor = connection.cursor()\n",
    "        postgres_insert_query = \"\"\"\n",
    "          \n",
    "          INSERT INTO monthly._log(\n",
    "            date, text)\n",
    "                VALUES (%s, %s);\n",
    "        \"\"\"\n",
    "    \n",
    "        record_to_insert = (str(datetime.datetime.now()),text)\n",
    "        \n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "    except(Exception, psycopg2.Error) as error:\n",
    "        if(connection):\n",
    "            print(\"Failed to insert log\", error)\n",
    "    finally:\n",
    "        if(connection):\n",
    "            cursor.close()\n",
    "            connection.close()                \n",
    "def isfloat(x):\n",
    "    try:\n",
    "        a = float(x)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def isint(x):\n",
    "    try:\n",
    "        a = float(x)\n",
    "        b = int(a)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    else:\n",
    "        return a == b\n",
    "def get_true_value(x):\n",
    "    x=str(x)\n",
    "    negative=False\n",
    "    if(',' in x):\n",
    "        x=x.replace(',','')\n",
    "    if('(' in x and ')' in x ):\n",
    "        x=x.replace(')','')\n",
    "        x=x.replace('(','')\n",
    "        negative=True\n",
    "    if isint(x):\n",
    "        x=x.split('.')[0]\n",
    "        if negative:\n",
    "            x=int(x)*-1\n",
    "        else:\n",
    "            x=int(x)\n",
    "    else:\n",
    "        if isfloat(x):\n",
    "            if negative:\n",
    "                x=float(x)*-1\n",
    "            else:\n",
    "                x=float(x)\n",
    "    return x    \n",
    "\n",
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start\n",
    "def FinWise10_NG_Product_desc(driver):\n",
    "    wholefile=str(driver.page_source)\n",
    "    wholefile=wholefile[wholefile.find('var datasource')+16:]\n",
    "    wholefile=wholefile[:wholefile.find('</script>')]\n",
    "    wholefile=wholefile.replace('\\u200c', '')\n",
    "    wholefile=wholefile.replace('\\n', '')\n",
    "    wholefile=wholefile.replace(';', '')\n",
    "    json1=json.loads(wholefile)\n",
    "    dict1=[]\n",
    "    counter=0\n",
    "    for k in json1['sheets'][0]['tables']:\n",
    "        if k['aliasName']=='ProductMonthlyActivityDesc1':\n",
    "            for t in k['cells']:\n",
    "                if counter%2==1:\n",
    "                    dict1.append(t['value'])\n",
    "                counter=counter+1\n",
    "    desc_titles=['desc_modif','desc_month','desc_year']\n",
    "    alldescs={}\n",
    "    desccounter=0\n",
    "    for i in range(len(dict1)):\n",
    "        alldescs[desc_titles[i]]=dict1[i]\n",
    "    if check_exists_by_xpath(driver,'//span[@id=\"ctl00_cphBody_ucNavigateToNextPrevLetter_lblCorrectionDesc\"]'):\n",
    "        alldescs['desc_title']=driver.find_element_by_xpath('//span[@id=\"ctl00_cphBody_ucNavigateToNextPrevLetter_lblCorrectionDesc\"]').text\n",
    "    else:\n",
    "        alldescs['desc_title']=\"\"\n",
    "    return alldescs\n",
    "def FinWise10_NewProduct(driver,CID):\n",
    "    newProduct_labels={\n",
    "        1:'good',\n",
    "        2:'unit',\n",
    "        3:'prev_production',\n",
    "        4:'prev_sale_count',\n",
    "        5:'prev_sale_rate',\n",
    "        6:'prev_sale_amount',\n",
    "        7:'modif_production',\n",
    "        8:'modif_salecount',\n",
    "        9:'modif_saleamount',\n",
    "        10:'prev_modified_production',\n",
    "        11:'prev_modified_sale_count',\n",
    "        12:'prev_modified_sale_rate',\n",
    "        13:'prev_modified_sale_amount',\n",
    "        14:'period_production',\n",
    "        15:'period_sale_count',\n",
    "        16:'period_sale_rate',\n",
    "        17:'period_sale_amount',\n",
    "        18:'total_production',\n",
    "        19:'total_sale_count',\n",
    "        20:'total_sale_rate',\n",
    "        21:'total_sale_amount',\n",
    "        22:'lastYear_production',\n",
    "        23:'lastYear_sale_count',\n",
    "        24:'lastYear_sale_rate',\n",
    "        25:'lastYear_sale_amount',\n",
    "        26:'status'\n",
    "    }\n",
    "    numerics={\n",
    "        3:'prev_production',\n",
    "        4:'prev_sale_count',\n",
    "        5:'prev_sale_rate',\n",
    "        6:'prev_sale_amount',\n",
    "        7:'modif_production',\n",
    "        8:'modif_salecount',\n",
    "        9:'modif_saleamount',\n",
    "        10:'prev_modified_production',\n",
    "        11:'prev_modified_sale_count',\n",
    "        12:'prev_modified_sale_rate',\n",
    "        13:'prev_modified_sale_amount',\n",
    "        14:'period_production',\n",
    "        15:'period_sale_count',\n",
    "        16:'period_sale_rate',\n",
    "        17:'period_sale_amount',\n",
    "        18:'total_production',\n",
    "        19:'total_sale_count',\n",
    "        20:'total_sale_rate',\n",
    "        21:'total_sale_amount',\n",
    "        22:'lastYear_production',\n",
    "        23:'lastYear_sale_count',\n",
    "        24:'lastYear_sale_rate',\n",
    "        25:'lastYear_sale_amount'\n",
    "    }\n",
    "    wholefile=str(driver.page_source)\n",
    "    wholefile=wholefile[(wholefile.find('\"cells\":['))+8:]\n",
    "    wholefile=wholefile[:wholefile.find('</script>')-10]\n",
    "    wholefile=wholefile[:wholefile.rfind(']')]\n",
    "    wholefile=wholefile[:wholefile.rfind(']')+1]\n",
    "    wholefile=wholefile.replace('[','')\n",
    "    wholefile=wholefile.replace(']','')\n",
    "    wholefile=wholefile.replace('\\u200c', '')\n",
    "    #wholefile=wholefile.replace('\"','\\'')\n",
    "    listofDicts=[]\n",
    "    for i in range(1,wholefile.count('value\"')+1):\n",
    "        start=find_nth(wholefile,'value\"',i)\n",
    "        end=find_nth(wholefile,'value\"',i)+50\n",
    "        wholefile=wholefile[:start]+(wholefile[start:end].replace('{',' '))+wholefile[end:]\n",
    "        wholefile=wholefile[:start]+(wholefile[start:end].replace('}',' '))+wholefile[end:]\n",
    "    for i in range(1,wholefile.count('{')+1):\n",
    "        try:\n",
    "            temp=wholefile[find_nth(wholefile,'{',i):find_nth(wholefile,'}',i)+1]\n",
    "            listofDicts.append(json.loads(temp))\n",
    "        except:\n",
    "            continue\n",
    "    df1=pd.DataFrame(listofDicts)\n",
    "    NEW=pd.DataFrame()\n",
    "    firstIter=True\n",
    "    for i in range(len(newProduct_labels.keys())):\n",
    "        category=df1[(df1['columnCode']==i+1)&(df1['valueTypeName']!='Blank')&(df1['rowTypeName']!='FixedRow')].sort_values(by='rowSequence').category.tolist()\n",
    "        temp_list=df1[(df1['columnCode']==i+1)&(df1['valueTypeName']!='Blank')&(df1['rowTypeName']!='FixedRow')].sort_values(by='rowSequence').value.tolist()\n",
    "        if (firstIter):\n",
    "            NEW[newProduct_labels[i+1]]=temp_list\n",
    "            NEW['Categories']=category\n",
    "        else:\n",
    "            if(len(temp_list)<len(NEW.index)):\n",
    "                for k in range(len(NEW.index)-len(temp_list)):\n",
    "                    temp_list.append('')\n",
    "            NEW[newProduct_labels[i+1]]=temp_list\n",
    "        firstIter=False\n",
    "    NEW=NEW[NEW['good']!='']\n",
    "    df_discount=df1[df1['category']==5][['value']].T\n",
    "    if not df_discount.empty:\n",
    "        df_discount.columns=newProduct_labels.values()\n",
    "        df_discount['Categories']=5\n",
    "        df_discount.reset_index(inplace=True)\n",
    "        df_discount.drop(columns='index',inplace=True)\n",
    "        NEW=NEW.append(df_discount)\n",
    "    Categoriesdf=pd.DataFrame.from_dict({1:'Domestic_Sale',2:'Export_Sale',3:'Service_revenue',4:'Refund',5:'Discount'  },orient='index')\n",
    "    Categoriesdf.reset_index(inplace=True)\n",
    "    Categoriesdf.columns=['Categories','categoryName']\n",
    "    NEW.replace('',0,regex=True,inplace=True)\n",
    "    NEW=NEW.replace('-Infinity',0)\n",
    "    NEW=NEW.replace('Infinity',0)\n",
    "    NEW=NEW.applymap(roundTheFloats)\n",
    "    NEW2=pd.merge(NEW,Categoriesdf,on='Categories')\n",
    "    NEW2.drop(columns=['Categories'],inplace=True)\n",
    "    NEW2.replace('ك','ک',regex=True,inplace=True)\n",
    "    NEW2.replace('ي','ی',regex=True,inplace=True)\n",
    "    for i in numerics.values():\n",
    "        NEW2[i] = NEW2[i].astype(str)\n",
    "        if i in NEW2.columns:\n",
    "            NEW2[i] = NEW2[i].str.replace(r'\\D+', '0')\n",
    "            NEW2[i]=NEW2[i].astype(int)\n",
    "    descdf=pd.DataFrame([FinWise10_NG_Product_desc(driver)])\n",
    "    # titlesdf=pd.DataFrame([titles])\n",
    "    # titlesdf.columns=['nemad','period','toDate','firm_reporting']\n",
    "    announcedf=pd.DataFrame([get_announcments(driver)])\n",
    "    NEW2['tmp'] = 1\n",
    "    descdf['tmp'] = 1\n",
    "    NEW2_1 = pd.merge(NEW2, descdf, on=['tmp'])\n",
    "    NEW2_1 = NEW2_1.drop('tmp', axis=1)\n",
    "    NEW2_1['tmp'] = 1\n",
    "    announcedf['tmp'] = 1\n",
    "    NEW2_3= pd.merge(NEW2_1, announcedf, on=['tmp'])\n",
    "    NEW2_3 = NEW2_3.drop('tmp', axis=1)\n",
    "    NEW2_3['report_id']=CID\n",
    "    NEW2_3=NEW2_3[(NEW2_3['good']!='')&(NEW2_3['good']!=None)&(NEW2_3['good']!='None')&(NEW2_3['good'].notnull())]\n",
    "    return NEW2_3\n",
    "def FinWise10_NewProductInsert(DF_Prod,CID,Clink):    \n",
    "    connection = psycopg2.connect(user=db_username,\n",
    "                                  password=db_pass,\n",
    "                                  host=db_host,\n",
    "                                  port=db_port,\n",
    "                                  database=db_database)\n",
    "    cursor = connection.cursor()\n",
    "    for index,row in DF_Prod.iterrows():\n",
    "        pq = \"\"\" \n",
    "        DO \n",
    "        $$\n",
    "        BEGIN\n",
    "            IF NOT EXISTS (select from monthly.goods where \"name\"=%s) THEN\n",
    "                INSERT INTO monthly.goods (\"name\",\"unit\") VALUES (%s,%s);\n",
    "            END IF;\n",
    "        END\n",
    "        $$\n",
    "        \"\"\"\n",
    "        rq = (row['good'],row['good'],row['unit'])\n",
    "        cursor.execute(pq, rq)\n",
    "    postgres_insert_query = \"\"\"\n",
    "     DO \n",
    "        $$\n",
    "        BEGIN\n",
    "            IF NOT EXISTS (select from monthly.\"productionMonthly\" where (\"report_id\"=%(report_id)s and \"good\"=(select \"ID\" from monthly.goods where name=%(good)s) and category=%(categoryName)s))THEN\n",
    "            INSERT INTO monthly.\"productionMonthly\"(\n",
    "\t good, desc_modification, \"desc_onePeriod\", \"desc_toDate\", desc_title, \"lastAnnouncment\", \"totalProductionPeriod\", \"totalSalePeriod\", \"saleRatePeriod\", \"saleAmountPeriod\", \"totalProductionYear\", \"totalSaleYear\", \"saleRateYear\", \"saleAmountYear\", \"prevTotalProductionYear\", \"prevTotalSalesYear\", \"prevTotalSalesRateYear\", \"prevTotalSalesAmountYear\", \"modification_Production\", \"modification_Sales\", \"modification_SalesAmount\", \"prev_modified_TotalProduction\", \"prev_modified_TotalSalesRate\", \"prev_modified_TotalSalesAmount\", \"prev_modified_TotalSales\", report_id, \"nextAnnouncement\", \"lastyear_Production\", \"lastyear_saleCount\", \"lastyear_saleAmount\", \"lastyear_saleRate\", category, status)\n",
    "                VALUES ((select \"ID\" from monthly.goods where name=%(good)s),\n",
    "                %(desc_modif)s, %(desc_month)s, %(desc_year)s, %(desc_title)s, %(Last)s, %(period_production)s, \n",
    "                %(period_sale_count)s, %(period_sale_rate)s, %(period_sale_amount)s, %(total_production)s, %(total_sale_count)s, %(total_sale_rate)s, \n",
    "                %(total_sale_amount)s, %(prev_production)s, %(prev_sale_count)s, %(prev_sale_rate)s, %(prev_sale_amount)s, %(modif_production)s, \n",
    "                %(modif_salecount)s, %(modif_saleamount)s, %(prev_modified_production)s, %(prev_modified_sale_rate)s, %(prev_modified_sale_amount)s, %(prev_modified_sale_count)s,\n",
    "                %(report_id)s, %(Next)s, %(lastYear_production)s, %(lastYear_sale_count)s, %(lastYear_sale_amount)s, \n",
    "                %(lastYear_sale_rate)s, %(categoryName)s, %(status)s);\n",
    "            END IF;\n",
    "        END\n",
    "        $$ \n",
    "\n",
    "    \"\"\"\n",
    "    cursor.executemany(postgres_insert_query,DF_Prod.to_dict(orient='records'))\n",
    "    connection.commit()\n",
    "    postgres_insert_query3 = \"\"\"\n",
    "    UPDATE monthly.\"PreMonthly\"\n",
    "    SET converted=True\n",
    "    WHERE \"report_ID\"=%(report_id)s\n",
    "    \"\"\"\n",
    "    cursor.executemany(postgres_insert_query3,DF_Prod.to_dict(orient='records'))\n",
    "    connection.commit()  \n",
    "    print(str(Clink)+'  '+'--Done')    \n",
    "def check_type(driver):\n",
    "    Type='Other'\n",
    "    typelist=['Other','1']\n",
    "    if check_exists_by_xpath(driver,'//table[@id=\"ctl00_cphBody_ucProduct2_Table1\"]'):\n",
    "        Type='Product'\n",
    "        prod_type=1\n",
    "        typelist=['Product',1]\n",
    "    if check_exists_by_xpath(driver,'//table[@id=\"ctl00_cphBody_ucProduct1_Table1\"]'):\n",
    "        Type='Product'\n",
    "        prod_type=2\n",
    "        typelist=['Product',2]\n",
    "    else:\n",
    "        if check_exists_by_xpath(driver,'//*[@id=\"ctl00_h1MasterTitle\"]'):\n",
    "            mastertitle=driver.find_element_by_xpath('//*[@id=\"ctl00_h1MasterTitle\"]').text\n",
    "            if mastertitle=='صورت وضعیت پورتفوی':\n",
    "                Type='Investment'\n",
    "                typelist=['Investment']\n",
    "    if (Type=='Other'):\n",
    "        wholefile=str(driver.page_source)\n",
    "        if('\"metaTableId' in wholefile):\n",
    "            Type='NewProduct'\n",
    "            typelist=['NewProduct']\n",
    "    return typelist           \n",
    "def RUN():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()                 \n",
    "    df=get_unconverted()\n",
    "    AllData=len(df.index)\n",
    "    counter=0\n",
    "    for index,row in df.head(2).iterrows():\n",
    "        try:\n",
    "            CodalRaw_ID=int(row['report_ID'])\n",
    "            CodalRaw_links=row['HtmlUrl']\n",
    "            #print(CodalRaw_ID)\n",
    "            driver.get('http://codal.ir'+CodalRaw_links)\n",
    "            time.sleep(3)\n",
    "            driver.execute_script(\"document.body.style.zoom='100%';document.body.style.zoom='50%'\")\n",
    "            # titles=get_titlebox()\n",
    "            # log_it('checked'+str(CodalRaw_ID))\n",
    "            Type=check_type(driver)\n",
    "            print(Type) \n",
    "            # if(Type[0]=='Product'):\n",
    "            #     #titles\n",
    "            #     alldesc=get_description_product_service()\n",
    "            #     Announcment=get_announcments()\n",
    "            #     DF_Prod=get_data_product(Type[1])\n",
    "            #     insertProduct(titles,Announcment,alldesc,DF_Prod,CodalRaw_ID,CodalRaw_links)\n",
    "            if(Type[0]=='NewProduct'):\n",
    "                DF_Prod=FinWise10_NewProduct(driver,CodalRaw_ID)\n",
    "                FinWise10_NewProductInsert(DF_Prod,CodalRaw_ID,CodalRaw_links)\n",
    "            #     InsertProductNG_ultimate(DF_Prod,CodalRaw_ID,CodalRaw_links)\n",
    "                #insertProduct(titles,Announcment,alldesc,DF_Prod,CodalRaw_ID,CodalRaw_links) \n",
    "            counter=counter+1\n",
    "            percentage=(counter*100)/AllData\n",
    "            print(\"{0:.2f}\".format(percentage))\n",
    "            \n",
    "        except (Exception, psycopg2.Error) as error :\n",
    "            print(error)\n",
    "            print(CodalRaw_links)\n",
    "            continue\n",
    "    # driver.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NewProduct']\n"
     ]
    }
   ],
   "source": [
    "RUN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676193  --Done\n",
      "100.00\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
